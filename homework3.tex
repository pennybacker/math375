\documentclass[12pt]{exam}

\usepackage{amssymb,amsfonts,amsmath}
\usepackage[letterpaper,margin=1in]{geometry}
\usepackage{graphicx}

\newcommand{\class}{MATH 375}
\newcommand{\term}{Fall 2016}
\newcommand{\doctitle}{Homework 3}

\parindent 0ex

\pagestyle{head}
\header{\bf \class}{\bf \doctitle\ - Page \thepage\ of \numpages}{\bf \term}
\headrule

\renewcommand{\arraystretch}{1.5}

\begin{document}

Remember to adequately label all plots and include any requested code listings with your solutions. \emph{Only include those scripts and functions which are requested}. A clear and complete presentation of your solutions is required for full credit.

\begin{questions}

\question Modify the provided \verb$newton$ function to display an appropriate error message when division by zero occurs or the maximum number of iterations is exceeded. Include the code for your modified function.

\question \textit{Accelerating Newton's Method Near Simple Roots}. One way to speed up the convergence of Newton's method is by using the Halley iteration formula
\[g(x) = x - \frac{f(x)}{f'(x)}\bigg(1-\frac{f(x)f''(x)}{2\,(f'(x))^2}\bigg)^{-1} .\]
The term in brackets is the modification of the Newton-Raphson formula.

\begin{parts}
\part Using the provided \verb$newton$ function as a starting point, write a function \verb$halley$ which implements this iteration. You will need an additional input \verb$fpp$ for a function handle to the second derivative $f''(x)$. Include the code for your function.
\part Using $f(x) = x^2-5$ and $x_0 = 2$, creating a table of values which demonstrates that Halley's method exhibits cubic convergence at simple roots of $f(x)$. The first column contains the iteration number $i$. The second column contains the error ratio $\varepsilon_{i+1} / \varepsilon_i^2$. The third column contains the error ratio $\varepsilon_{i+1} / \varepsilon_i^3$. The fourth column contains the error ratio $\varepsilon_{i+1} / \varepsilon_i^4$. Note that the method should converge after just a few iterations. All numerical values should be printed to at least 10 digits. Explain briefly how your data demonstrate cubic convergence.
\part Discuss the trade-offs associated with using this method instead of Newton's method. That is, why would you want to use one instead the other and vice versa?
\end{parts}

\question \textit{Accelerating Newton's Method Near Multiple Roots}. If the order of a root is known, it is possible to avoid the loss of quadratic convergence associated with a multiple root in the following way. Recall that if $r$ is a root of order $m$, then the $k$-th derivative $f^{(k)}(r) = 0$ for all $k < m$.
\begin{parts}
\part Suppose that $r$ is a root of $f(x)$ with order $m$. Prove that the modified Newton-Raphson iteration
\[x_k = x_{k-1}-\frac{m\,f(x_{k-1})}{f'(x_{k-1})}\]
converges quadratically. Also find the limiting error ratio $\varepsilon_{i+1}/\varepsilon_i^2$ as $i \rightarrow \infty$.
\part Discuss the trade-offs associated with using this method instead of Newton's method. That is, why would you want to use one instead the other and vice versa?
\end{parts}

\newpage

\question \textit{Accelerating Newton's Method Near Multiple Roots, Part 2}. Here is another way of accelerating Newton's method that does not require knowing the order of a root ahead of time. Recall that if $r$ is a root of order $m$, then $f(x) = (x-p)^m q(x)$ with $q(r) \neq 0$.

\begin{parts}
\part Show that $h(x) = f(x)/f'(x)$ has a simple root at $r$.
\part Show that when the Newton-Raphson iteration is applied to finding the simple root $r$ of $h(x)$ we get $g(x) = h(x)/h'(x)$ which becomes
\[g(x) = x-\frac{f(x)f'(x)}{(f'(x))^2 - f(x)f''(x)} .\]
\part The iteration using $g(x)$ converges quadratically to $r$. Explain why this happens.
\part Discuss the trade-offs associated with using this method instead of Newton's method. That is, why would you want to use one instead the other and vice versa? 
\end{parts}

\question \textit{Order of Convergence for the Secant Method}. Recall that if an iterative method converges with order $p$, we have
\[\frac{\varepsilon_{i+1}}{\varepsilon_i^p} \approx M \quad\text{and}\quad \frac{\varepsilon_{i+2}}{\varepsilon_{i+1}^p} \approx M\]
as $i \rightarrow \infty$ for some rate $M < \infty$.

\begin{parts}
\part By setting the two ratios equal to each other and taking logarithms, show that
\[p \approx \frac{\log \varepsilon_{i+2}-\log \varepsilon_{i+1}}{\log\varepsilon_{i+1}-\log\varepsilon_i} ,\]
thus giving us a procedure to estimate $p$.
\part Using the provided \verb$newton$ function as a starting point, write a function \verb$secant$ which implements the secant method. You will need an additional input \verb$x1$ for the second initial guess, and you won't need the input \verb$fp$. The objective function \verb$f$ should only be evaluated once per iteration. Include the code for your function.
\part Devise an experiment using the estimate above to show that the secant method converges with order $p = (1+\sqrt{5})/2 \approx 1.6180$ to a simple root of $f(x)$. Include your objective function, initial guesses, and a table of your estimates of $p$ at each iteration.
\end{parts}

\end{questions}

\end{document}
